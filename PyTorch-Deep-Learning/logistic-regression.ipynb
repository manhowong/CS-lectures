{"cells":[{"cell_type":"markdown","metadata":{"id":"OZ0S8IQWfTTV"},"source":["# Logistic Regression with PyTorch\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BlizBg8UfTTV"},"source":["## Example: Image classification of MNIST handwritten digits\n","\n","Dataset: [*MNIST Handwritten Digits Database*](http://yann.lecun.com/exdb/mnist/) (28px by 28px grayscale images of handwritten digits and labels)\n","\n","![mnist-sample](https://i.imgur.com/CAYnuo1.jpg)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"o_xViEWvfTTV","executionInfo":{"status":"ok","timestamp":1703296717814,"user_tz":300,"elapsed":177,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}}},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision.datasets import MNIST\n","import torchvision.transforms as transforms # transform images into tensors\n","import torch.nn.functional as F # contains softmax function, cross entropy, etc.\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Download training dataset and test dataset\n","# Note: MNIST automatically create a PyTorch Dataset object\n","\n","dataset = MNIST(root='data/', download=True) # set download=True to save on disk\n","test_dataset = MNIST(root='data/', train=False) # set train=False for test dataset\n","\n","# len(dataset) # training dataset has 60000 images\n","# len(test_dataset) # test dataset has 10000 images"],"metadata":{"id":"0xgE7cZ7blK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"hYvBQ3LzfTTX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703296970547,"user_tz":300,"elapsed":137,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}},"outputId":"9f1d8332-9148-41e2-dd70-8b98d1452943"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 28, 28])\n"]}],"source":["# Download dataset (images + labels) and convert images to tensors\n","dataset = MNIST(root='data/', train=True,\n","                transform=transforms.ToTensor())\n","\n","# Each image is represented by a 1x28x28 tensor (greyscale image has only 1 channel, so the size of the first dimension is 1)\n","img_tensor, label = dataset[0]\n","print(img_tensor.shape)"]},{"cell_type":"markdown","metadata":{"id":"qSKTZ8aifTTX"},"source":["## Preparing the training and validation datasets\n","\n","\n","1. **Training set** - used to train the model, i.e., compute the loss and adjust the model's weights using gradient descent.\n","2. **Validation set** - used to evaluate the model during training, adjust hyperparameters (learning rate, etc.), and pick the best version of the model.\n","3. **Test set** - used to compare different models or approaches and report the model's final accuracy.\n","\n","  In the MNIST dataset, there are 60,000 training images and 10,000 test images. The test set is standardized so that different researchers can report their models' results against the same collection of images."]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":154,"status":"ok","timestamp":1703296973180,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"},"user_tz":300},"id":"1dcE0OPBfTTX"},"outputs":[],"source":["# Split data into training and validation datasets randomly\n","from torch.utils.data import random_split\n","\n","train_ds, val_ds = random_split(dataset, [50000, 10000])\n","\n","# Create data loader\n","from torch.utils.data import DataLoader\n","\n","batch_size = 128\n","train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n","val_loader = DataLoader(val_ds, batch_size) # no need to shuffle validation data since it's for evaluation only"]},{"cell_type":"markdown","metadata":{"id":"Fy-lajKQfTTY"},"source":["## Model\n","\n","* A **logistic regression** model is almost identical to a linear regression model. It contains weights and bias matrices, and the output is obtained using simple matrix operations (`pred = x @ w.t() + b`).\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"zzVbD7pifTTY","executionInfo":{"status":"ok","timestamp":1703296975281,"user_tz":300,"elapsed":335,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}}},"outputs":[],"source":["# Define a logistic regression model\n","# Note: this step is the same as a linear regression model\n","\n","import torch.nn as nn\n","\n","input_size = 28*28  # each pixel is an input\n","num_classes = 10    # 10 target labels (digits 0 to 9)\n","\n","model = nn.Linear(input_size, num_classes)\n","# Alternatively, we can define a custom model class as follows\n","################################################################################\n","\n","# Create a custom model class by extending the class nn.Module\n","class MnistModel(nn.Module):\n","    def __init__(self):\n","        super().__init__() # call the constructor of the super class, nn.Module\n","        self.linear = nn.Linear(input_size, num_classes)\n","\n","    def forward(self, xb): # this method takes a batch of dataset (xb)\n","        # We need to first flatten the input tensor (xb) first from Nx28x28 to Nx784 (N is the batch size, i.e. no. of images)\n","        # becasue the model can only take Nx784 input tensor\n","        xb = xb.reshape(-1, 784) # flatten xb (set first dimension (batch size) to -1 so PyTorch will detect it automatically)\n","        out = self.linear(xb)\n","        return out\n","\n","model = MnistModel()"]},{"cell_type":"code","source":["# Note that the .weight and .bias attributes are now inside the model's .linear attribute, but the `.parameters` method still works\n","# print(model.linear.weight.shape, model.linear.bias.shape)\n","# list(model.parameters())"],"metadata":{"id":"pS9yfzWEpdRx","executionInfo":{"status":"ok","timestamp":1703296976977,"user_tz":300,"elapsed":185,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hTgl76MgfTTZ"},"source":["## Training the model\n","\n","The training process is identical to linear regression, with the addition of a \"validation phase\" to evaluate the model in each epoch:\n","\n","```\n","for epoch in range(num_epochs):\n","    # Training phase\n","    for batch in train_loader:\n","        # Generate predictions\n","        # Calculate loss\n","        # Compute gradients\n","        # Update weights\n","        # Reset gradients\n","    \n","    # Validation phase\n","    for batch in val_loader:\n","        # Generate predictions\n","        # Calculate loss\n","        # Calculate metrics (accuracy etc.)\n","    # Calculate average validation loss & metrics\n","    \n","    # Log epoch, loss & metrics for inspection\n","```\n","\n","### Loss Function and Evaluation Metric\n","\n","- **Loss function**: to assess the prediction loss during training phase\n","- **Evaluation metric**: to evaluate the performance of the model during validation phase\n","\n","- For evaluation metric, we can use **accuracy**:\n","\n","  ```accuracy = number of correctly predicted labels / total number of labels```\n","\n","- Note: Accuracy is easy for human to understand, but can't be used as a loss function because 1) it's not differentiable; 2) it's either correct or incorrect, not taking probability into consideration*\n","\n","- For loss function, a commonly used function for classification problems is the **cross-entropy**:\n","\n","  ![cross-entropy](https://i.imgur.com/VDRDl1D.png)\n","  \n","  - For each output row, pick the probability for the correct label ($ŷ$)\n","  - take the logarithm of $ŷ$. If the probability is high, i.e., close to 1, then its logarithm is a very small negative value, close to 0. Vice versa.\n","  - multiply the result by -1 so the result is positive (the larger the value the higher the \"loss\")\n","  - Finally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data\n","  - PyTorch has a built-in function for cross entropy:\n","    ```F.cross_entropy(output, labels)```\n","\n","### Implementation\n","\n","- Some parts of the training are specific to problem we're solving (e.g. loss function, metrics etc.) whereas others are generic.\n","- The problem-specific parts will be implemented by adding new methods to the `nn.Module` class.\n","- The generic parts will be included in the custom function `fit` as follows:"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"1cv7a7ukfTTZ","executionInfo":{"status":"ok","timestamp":1703296981036,"user_tz":300,"elapsed":200,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}}},"outputs":[],"source":["def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n","    optimizer = opt_func(model.parameters(), lr)\n","    history = [] # record epoch-wise results (validation loss and metric) for debugging & visualization\n","\n","    for epoch in range(epochs):\n","\n","        # Training Phase\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","\n","    return history\n","\n","def evaluate(model, val_loader):\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)"]},{"cell_type":"code","source":["# The problem-specific functions (e.g. loss function, metric) are implemented by\n","# extending the nn.Module\n","\n","class MnistModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(input_size, num_classes)\n","\n","    def forward(self, xb):\n","        xb = xb.reshape(-1, 784)\n","        out = self.linear(xb)\n","        return out\n","\n","    def training_step(self, batch):\n","        images, labels = batch\n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","\n","    def validation_step(self, batch):\n","        images, labels = batch\n","        out = self(images)                    # Generate predictions\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss, 'val_acc': acc}\n","\n","    def validation_epoch_end(self, outputs):\n","        # Calculate average validation loss & metrics\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","\n","    def epoch_end(self, epoch, result):\n","        # Print results\n","        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n","\n","# compute accuracy\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"],"metadata":{"id":"4Fl6ihACjewo","executionInfo":{"status":"ok","timestamp":1703296982097,"user_tz":300,"elapsed":203,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KapQW0CDfTTZ"},"source":["Choose the hyperparameters (e.g. batch size, learning rate, etc.) that give you a reasonably accurate model within a reasonable amount of training time."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":80103,"status":"ok","timestamp":1703296804562,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"},"user_tz":300},"id":"MQRahsa6fTTZ","outputId":"b6bc3958-5da1-4fab-8e8e-2059e2130c7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [0], val_loss: 1.9484, val_acc: 0.6310\n","Epoch [1], val_loss: 1.6771, val_acc: 0.7237\n","Epoch [2], val_loss: 1.4747, val_acc: 0.7582\n","Epoch [3], val_loss: 1.3217, val_acc: 0.7801\n","Epoch [4], val_loss: 1.2043, val_acc: 0.7956\n","Epoch [5], val_loss: 1.1121, val_acc: 0.8064\n","Epoch [6], val_loss: 1.0382, val_acc: 0.8142\n","Epoch [7], val_loss: 0.9777, val_acc: 0.8200\n","Epoch [8], val_loss: 0.9274, val_acc: 0.8243\n","Epoch [9], val_loss: 0.8849, val_acc: 0.8277\n"]}],"source":["model = MnistModel()\n","history = fit(10, 0.001, model, train_loader, val_loader)"]},{"cell_type":"markdown","metadata":{"id":"HXgOorOIfTTa"},"source":["## Testing with individual images"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"KqcHUQK3fTTa","executionInfo":{"status":"ok","timestamp":1703296804563,"user_tz":300,"elapsed":24,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}}},"outputs":[],"source":["# Define test dataset\n","test_dataset = MNIST(root='data/',\n","                     train=False,\n","                     transform=transforms.ToTensor())"]},{"cell_type":"markdown","metadata":{"id":"QgwbsDUjfTTa"},"source":["Let's define a helper function `predict_image`, which returns the predicted label for a single image tensor."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"9FfeYQaOfTTa","executionInfo":{"status":"ok","timestamp":1703296804564,"user_tz":300,"elapsed":24,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}}},"outputs":[],"source":["def predict_image(img, model):\n","    xb = img.unsqueeze(0) # because we are only using one image here, we make xb as a batch containing only one image\n","    yb = model(xb)\n","    _, preds = torch.max(yb, dim=1)\n","    return preds[0].item()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1703296804976,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"},"user_tz":300},"id":"sPNcp52ifTTa","outputId":"28db137b-2a82-4157-e3d5-8433dced0c1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Label: 7 , Predicted: 7\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["img, label = test_dataset[0]\n","plt.imshow(img[0], cmap='gray')\n","print('Label:', label, ', Predicted:', predict_image(img, model))"]},{"cell_type":"markdown","metadata":{"id":"TqC3HEZJfTTb"},"source":["## Saving and loading the model"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"xESC-106fTTb","executionInfo":{"status":"ok","timestamp":1703296804976,"user_tz":300,"elapsed":16,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}}},"outputs":[],"source":["torch.save(model.state_dict(), 'mnist-logistic.pth')"]},{"cell_type":"markdown","metadata":{"id":"Qc9kRTDpfTTb"},"source":["To load the model parameters, we can instantiate a new `MnistModel` object, and use the `.load_state_dict` method."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"OO666r7_1rbW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703296804977,"user_tz":300,"elapsed":16,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}},"outputId":"db5de98a-71ad-4574-a0da-1ebf7c051f43"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":19}],"source":["model2 = MnistModel()\n","model2.load_state_dict(torch.load('mnist-logistic.pth'))"]},{"cell_type":"markdown","metadata":{"id":"9v407S1jfTTZ"},"source":["## Use softmax function to convert outputs to probabilities\n","\n","The model outputs are sets (rows) of scores (each image has a set of 10 scores for 10 labels).\n"]},{"cell_type":"code","source":["for batch in train_loader:\n","  images, labels = batch\n","  break\n","outputs = model(images)\n","print(outputs[0]) # print the first output row"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6X0N-jBweTL","executionInfo":{"status":"ok","timestamp":1703296804563,"user_tz":300,"elapsed":32,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}},"outputId":"9010ff01-caa6-4f1a-d8c0-bb38478b9fd5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-1.7066,  2.6493,  1.4319,  0.2146, -0.8657, -0.4553, -0.7649, -0.7703,\n","         1.4952, -0.5174], grad_fn=<SelectBackward0>)\n"]}]},{"cell_type":"markdown","source":["\n","\n","We can convert the outputs to probabilities using softmax:\n","\n","- raise each output score $y_i$ to $e^{y_i}$, making it positive.\n","- normalize $e^{y_i}$ by the sum of the corresponding set of raised scores\n","- the result can be interpreted as a probability\n","\n","![softmax](https://i.imgur.com/EAh9jLN.png)\n","\n"],"metadata":{"id":"Gg6RTVYwxSFA"}},{"cell_type":"code","source":["# Apply softmax for each output row\n","probs = F.softmax(outputs, dim=1) # dim specifies the dimension to which softmax is applied\n","\n","# Get the max probability in each row and the corresponding label (i.e. the prediction)\n","max_probs, preds = torch.max(probs, dim=1) # set dim to 1 to get the max value in each row\n","max_probs, preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdmuQBNuqgNc","executionInfo":{"status":"ok","timestamp":1703296804563,"user_tz":300,"elapsed":28,"user":{"displayName":"Man Ho Wong","userId":"01009376394376826107"}},"outputId":"0f6aa1f8-3532-425d-c76c-89b893bee91f"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.5279, 0.2450, 0.3406, 0.4394, 0.3002, 0.4449, 0.7698, 0.2968, 0.5912,\n","         0.4003, 0.2257, 0.2599, 0.5257, 0.8029, 0.2612, 0.2888, 0.2729, 0.7008,\n","         0.2477, 0.7913, 0.9432, 0.2209, 0.9592, 0.5319, 0.6146, 0.3315, 0.8711,\n","         0.6532, 0.6159, 0.5654, 0.2273, 0.6751, 0.2801, 0.5639, 0.5081, 0.6516,\n","         0.2648, 0.2179, 0.4363, 0.3765, 0.5063, 0.6902, 0.3839, 0.3507, 0.3076,\n","         0.6982, 0.5512, 0.4658, 0.6629, 0.2618, 0.7270, 0.5379, 0.8537, 0.2850,\n","         0.5156, 0.5273, 0.3530, 0.7766, 0.6358, 0.3417, 0.3918, 0.4233, 0.4339,\n","         0.2173, 0.6347, 0.3655, 0.8727, 0.9002, 0.2886, 0.2251, 0.2613, 0.6275,\n","         0.5083, 0.7619, 0.7545, 0.2018, 0.2734, 0.7144, 0.8119, 0.6146, 0.4069,\n","         0.3731, 0.7856, 0.7367, 0.7800, 0.1959, 0.5482, 0.7851, 0.5913, 0.2812,\n","         0.4486, 0.3905, 0.7791, 0.5198, 0.2826, 0.4209, 0.5833, 0.4126, 0.4093,\n","         0.3891, 0.6720, 0.2053, 0.2923, 0.4135, 0.4115, 0.6647, 0.3647, 0.3268,\n","         0.3723, 0.3376, 0.4861, 0.5060, 0.2519, 0.4561, 0.3246, 0.5091, 0.5928,\n","         0.2745, 0.7057, 0.6990, 0.2170, 0.2311, 0.7149, 0.7563, 0.7498, 0.6619,\n","         0.4683, 0.6464], grad_fn=<MaxBackward0>),\n"," tensor([1, 3, 2, 0, 8, 7, 2, 3, 1, 2, 4, 1, 7, 7, 2, 9, 9, 4, 0, 0, 0, 6, 0, 2,\n","         4, 8, 0, 2, 9, 3, 4, 8, 8, 3, 8, 1, 8, 5, 8, 7, 5, 6, 4, 5, 3, 1, 4, 4,\n","         1, 5, 1, 1, 0, 2, 7, 9, 1, 6, 7, 7, 4, 7, 0, 5, 8, 0, 2, 0, 9, 5, 8, 6,\n","         8, 1, 1, 3, 9, 3, 0, 3, 3, 2, 0, 0, 2, 8, 1, 0, 3, 8, 1, 3, 6, 5, 0, 4,\n","         3, 8, 4, 1, 7, 0, 5, 4, 9, 3, 4, 9, 1, 1, 3, 8, 2, 8, 3, 5, 6, 6, 3, 8,\n","         3, 9, 7, 0, 0, 3, 9, 2]))"]},"metadata":{},"execution_count":14}]}],"metadata":{"colab":{"provenance":[{"file_id":"1OTT5phOk8Vsjv14QM-wpCykyypXGsDRD","timestamp":1703262247110}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}